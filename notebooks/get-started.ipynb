{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guild AI Interactive Python Quick Start\n",
    "\n",
    "This Notebook mirrors the steps in [Guild AI Quick Start](https://guild.ai/docs/start/).\n",
    "\n",
    "Guild AI is a tool for running, tracking, and comparing machine learning experiments. For more on Guild AI, visit https://guild.ai.\n",
    "\n",
    "In this example, we show how Guild is used to run an unmodified Python function as a training operation. It uses a Pythonic interface defined in the module `guild.ipy`.\n",
    "\n",
    "This notebook covers the following topics:\n",
    "\n",
    "- Installation\n",
    "- Experiment basics\n",
    "    - Create a mock training function\n",
    "    - Generate a run with Guild\n",
    "    - Examine the run\n",
    "    - Generate a second run\n",
    "    - Compare runs\n",
    "- Hyperparameter search and optimization\n",
    "    - Grid search\n",
    "    - Random search\n",
    "    - Bayesian optimization\n",
    "\n",
    "## Installation\n",
    "\n",
    "Before continuing, install Guild AI:\n",
    "\n",
    "    $ pip install guildai\n",
    "    \n",
    "Install either `tensorflow` or `tensorflow-gpu` depending on your system capability:\n",
    "\n",
    "    $ pip install tensorflow # (or tensorflow-gpu if your system has a GPU)\n",
    "    \n",
    "TensorFlow is required for TensorBoard support. Your training code does not need to use TensorFlow. This requirement will be removed in versions of Guild starting with `0.7`.\n",
    "    \n",
    "<span style=\"color:#600;font-weight:600\">IMPORTANT</span> If you are installing Guild AI 0.6.3, you must manually install a missing requirement (this bug is fixed in 0.6.4, which will be released in late May):\n",
    "\n",
    "    $ pip install click\n",
    "    \n",
    "## Contents\n",
    "    \n",
    "This Notebook has two parts.\n",
    "\n",
    "It features the module `guild.ipy`, which is a Python interface that can be used interactively in Notebooks or by your own Python code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks config\n",
    "\n",
    "Modify the variables below to change Notebook configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GULID_HOME` is the location of generated runs. By default it is the location subdirectory \"guild-env\". Note that we initialize this directory below by permanently deleting any runs it contains before proceeding. If you don't want to delete runs in `GUILD_HOME`, set `DELETE_RUNS_ON_INIT` to `False` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GUILD_HOME = \"guild-env\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DELETE_RUNS_ON_INIT` determines whether or not runs are initially deleted from `GUILD_HOME` below. As this Notebook is for demonstration purposes, it's usually a good idea to delete any existing runs before proceeding. To prevent any runs from being deleted, set `DELETE_RUNS_ON_INIT` to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETE_RUNS_ON_INIT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guild interactive Python API\n",
    "\n",
    "Guild AI functionality is available through a Notebook compatible interface defined in `guild.ipy`.\n",
    "\n",
    "Import this module as `guild`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import guild.ipy as guild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#600;font-weight:600\">IMPORTANT</span> If you get an error **No module named 'click'** install `click` manually by running `pip install click` in your Notebook environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Guild Home\n",
    "\n",
    "Guild home is a directory containing the runs that Guild generates. This Notebook uses the directory defined by `GUILD_HOME`. Ensure that the directory exists and use `set_guild_home()` to set the value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists(GUILD_HOME):\n",
    "    os.mkdir(\"guild-env\")\n",
    "    \n",
    "guild.set_guild_home(\"guild-env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear the director of any runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DELETE_RUNS_ON_INIT:\n",
    "    deleted = guild.runs().delete(permanent=True)\n",
    "    print(\"Deleted %i run(s)\" % len(deleted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock training function\n",
    "\n",
    "Create a mock training script. This function doesnâ€™t actually train anything, but simulates the training process of accepting hyperparameters as inputs and generating a loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def train(x=0.1, noise=0.1):\n",
    "    loss = (np.sin(5 * x) * (1 - np.tanh(x ** 2)) + np.random.randn() * noise)\n",
    "    print(\"loss: %f\" % loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Function credit: *skopt API documentation*](https://scikit-optimize.github.io/)\n",
    "\n",
    "Run the mock training function a couple times to see how it works.\n",
    "\n",
    "**NOTE** The function uses a random component to simulate training \"noise\". This causes the results to differ across runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trial 1:\")\n",
    "train(x=-2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trial 2:\")\n",
    "train(x=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Trial 3:\")\n",
    "train(x=2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the mock train function using Guild:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run, return_val = guild.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run()` function returns a tuple of the Guild run and the return value of the function.\n",
    "\n",
    "In this case, our mock training function doesn't return a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(return_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run` variable is a Python object that represents the run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work with the run object directly to get information about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each run has a uniqiue ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each run is associated with a unique directory, which includes the ID. The run directory contains metadata and output associated with the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our mock training script doesn't generate any files, so the run directory is empty, with the exception of a `.guild` subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(run.dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.guild` subdirectory contains run output and metadata. Outputs include the output printed to the script during the operation (`output`) and any scalars logged (`events.*`). Guild logs scalar output using TensorFlow event files, which can be read using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(run.dir, \".guild\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run metadata includes *attributes*. You can list the attribute names using `attr_names()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.attr_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read an attribute value using `get()`. For example, to read the *flags* attribute, use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get(\"flags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flags are values provided to the function. In this case, both values are defined as function keyword default values. Later you run `train` using explicit flag values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each run has a *status*, which indicates if the run is still running and whether or not it completed successfully or terminated with an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List runs using `guild.runs()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = guild.runs()\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each time you run an operation, the run appears in the data frame generated by `runs()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print run info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `runs`, we can print information for the latest run using `runs.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This information reflects the information you saw in the prior section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scalars\n",
    "\n",
    "Run results are recorded as *scalars*. You can list scalars in two ways.\n",
    "\n",
    "First, you can specify the `scalars` flag to `info()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs.info(scalars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, you can get a data frame containing scalars using the `scalars()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars = runs.scalars()\n",
    "scalars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#600;font-weight:600\">IMPORTANT</span> If this listing is empty, ensure that you have TensorFlow installed (see above for instructions).\n",
    "\n",
    "Guild stores aggregates of each tag, including *first*, *last*, *max*, *min*, and *average*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the various facilities in data frame to get scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalars.query(\"(run == '%s') and (tag == 'loss')\" % run.id)[\"last_val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a second run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run train again with different flags along with a run *label*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = guild.run(train, x=0.2, _label=\"run 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the latest run contains the label \"run 2\" as specified in the `run()` call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare runs\n",
    "\n",
    "Use `compare()` to generate a data frame containing both flags and scalars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search\n",
    "\n",
    "Grid search &mdash; also referred to as a parameter sweep &mdash; is a form of hyperparameter tuning that uses exhaustive search over a manually defined set of hyperparameter values.\n",
    "\n",
    "To perform a grid search in Guild, provide a list of values to use for any given flag. If you specify lists for multiple flags, Guild runs trials for each possible flag value combination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `train()` using a range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = guild.run(train, x=[-0.5,-0.4,-0.3,-0.2,-0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command generates five trials, one for each specified value of `x`.\n",
    "\n",
    "Use `runs().compare()[:5]` to compare the last five results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the top-three results by loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare().sort_values(by=\"loss\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our mock training function, the \"best\" result (i.e. the run with the lowest *loss*) should be the run where `x` is close to `-0.3`. Because there's a random component (i.e. the `noise` parameter) your results may show best results with different values for `x`.\n",
    "\n",
    "Below is an image that plots *loss* for values of *x*, showing the lowest loss where x is approximately `-0.3`.\n",
    "\n",
    "<img src=\"bayesian-optimization.png\" style=\"margin-left:0\">\n",
    "\n",
    "[Image credit: *Bayesian optimization with skopt*](https://scikit-optimize.github.io/notebooks/bayesian-optimization.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random search\n",
    "\n",
    "Random search is a method used in machine learning to explore hyperparameter spaces at random.\n",
    "\n",
    "To run a series of runs using random values over a specified range, use the `slice` function to specify a range for a flag. To specify the number of trials, specify `_max_trials`. The default number of trials is `20`.\n",
    "\n",
    "Run train five times with random values of `x` over the range `-2.0` to `2.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = guild.run(train, x=slice(-2.0,2.0), _max_trials=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the three runs with the lowest loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare().sort_values(by=\"loss\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian optimization\n",
    "\n",
    "Bayesian optimizers use light weight models as surrogates for the target model â€” surrogates that can be evaluated quickly to recommend likely optimal hyperparameter values â€” and update those models using results from real trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `train` with Guildâ€™s built-in Bayesian optimizer, which uses Gaussian processes. As with the earlier random search, we use Python's slice function to specify the range for `x` over which to search.\n",
    "\n",
    "**NOTE:** The argument `bayesian` in the command is an alias for `gp`, which is a Bayesian optimizer that uses Gaussian processes. Guild supports three Bayesian optimizers: gp, forest and gbrt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = guild.run(train, x=slice(-2.0,2.0), _optimizer=\"bayesian\", _max_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the top 10 results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guild.runs().compare().sort_values(by=\"loss\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This Notebook covers basic functionality provided by the `guild.ipy` module. The module lets you run functions and capture results as unique runs. You can view and compare run results using various module functions.\n",
    "\n",
    "Generated runs can be further managed using the Guild command line interface. For more information, refer to [Guild AI Quick Start](https://guild.ai/docs/start/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "guild",
   "language": "python",
   "name": "guild"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
